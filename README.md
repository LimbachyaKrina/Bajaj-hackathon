# Bajaj Hackathon Project

## ğŸš€ Project Overview
This project is designed as a modular Retrieval-Augmented Generation (RAG) system, featuring a FastAPI backend, a Streamlit frontend, and benchmarking tools. It enables users to query documents (such as policies) using advanced LLMs, with a focus on performance, flexibility, and ease of use.

## ğŸ› ï¸ Features & Workflow
- **Document Ingestion**: Upload and process documents (e.g., PDFs) for retrieval.
- **RAG Pipeline**: Retrieve relevant document chunks and generate answers using LLMs.
- **API Backend**: FastAPI server exposes endpoints for querying and managing the pipeline.
- **Frontend**: (Optional) Streamlit app for interactive querying and visualization.
- **Benchmarking**: Evaluate the performance and accuracy of the RAG pipeline.

### Typical Workflow
1. **Setup**: Install dependencies and configure environment variables.
2. **Start Backend**: Launch the FastAPI server to serve the RAG API.
3. **(Optional) Start Frontend**: Use the Streamlit app for a user-friendly interface.
4. **Query**: Send questions to the API or frontend; receive LLM-generated answers with supporting context.
5. **Benchmark**: Run benchmarking scripts to evaluate system performance.

## ğŸ“ Project Structure
```
â”œâ”€â”€ venv/                 # Virtual environment
â”œâ”€â”€ main.py               # FastAPI application (backend)
â”œâ”€â”€ rag_pipeline.py       # RAG processing logic
â”œâ”€â”€ responder.py          # LLM response generation
â”œâ”€â”€ utils.py              # Utility functions
â”œâ”€â”€ streamlit_app.py      # Streamlit web interface (optional)
â”œâ”€â”€ benchmarking.py       # Performance evaluation scripts
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ activate_venv.bat     # Windows activation script
â”œâ”€â”€ Datasets/             # Example datasets (e.g., policy.pdf)
â”œâ”€â”€ metadata.pkl          # Metadata for document processing
â”œâ”€â”€ README.md             # Project documentation
```

## âš™ï¸ Setup Instructions

### 1. Clone the Repository
```bash
git clone <your-repo-url>
cd <project-directory>
```

### 2. Create and Activate Virtual Environment
**On Windows (PowerShell):**
```powershell
python -m venv venv
venv\Scripts\Activate.ps1
```
**On Windows (Command Prompt):**
```cmd
venv\Scripts\activate.bat
```
**Or simply double-click:**
```
activate_venv.bat
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Set Environment Variables
Create a `.env` file in the project root:
```
RAY_OPENAI_API_KEY=your_openai_api_key_here
```

## â–¶ï¸ Usage

### 1. Start the FastAPI Backend
```bash
python main.py
```
The API will be available at: [http://localhost:8000](http://localhost:8000)

### 2. (Optional) Run the Streamlit Frontend
```bash
streamlit run streamlit_app.py
```

### 3. (Optional) Run Benchmarking
```bash
python benchmarking.py
```

### 4. Deactivate the Virtual Environment
```bash
deactivate
```

## ğŸ”‘ Environment Variables
- `RAY_OPENAI_API_KEY`: Your OpenAI API key for LLM access. Required for backend operation.

## ğŸ¤ Contributing
Pull requests and issues are welcome! Please open an issue to discuss your ideas or report bugs before submitting a PR.

## ğŸ“„ License
Specify your license here (e.g., MIT, Apache 2.0, etc.)

---

**Contact:** For questions or support, please contact the project maintainer.
